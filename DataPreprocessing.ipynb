{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing using Machine Learning & Artificial Intelligence"
      ],
      "metadata": {
        "id": "kXRqyz1fAwUC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libraries\n"
      ],
      "metadata": {
        "id": "gR2Tm6MqA7ej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "nF1w3_lmA6Wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Now we are going to implement some data sets.\n",
        "- Here, we are applying the iloc function for data analysis & manipulation which mainly stands for \"Integer Location\".\n",
        "- Applying slicing to get the data according to the patients who needed to go hospital."
      ],
      "metadata": {
        "id": "TmsNNYAjDtUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('Covid_Data_new.csv')\n",
        "a = data.iloc[:, :-1].values\n",
        "b = data.iloc[:, -1].values"
      ],
      "metadata": {
        "id": "riZvce_UETTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(a)"
      ],
      "metadata": {
        "id": "FfecEwQVGZ4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(b)"
      ],
      "metadata": {
        "id": "4IAE3ijNGbau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- As we can see there are few rows with missing values, so we need to fill up the values using imputer tranform from sklearn.impute.\n",
        "- Since, they are in combination of integer and string so we need to apply the function twice."
      ],
      "metadata": {
        "id": "jRmmCkipJA9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.core import missing\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(missing_values = np.nan, strategy = 'mean')\n",
        "\n",
        "imputer.fit(a[:, 0:1])\n",
        "a[:, 0:1] = imputer.transform(a[:, 0:1])"
      ],
      "metadata": {
        "id": "hK1F9Y-gLKLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(a)"
      ],
      "metadata": {
        "id": "y-Lw-VvMNb8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imputer.fit(a[:, 4:5])\n",
        "a[:, 4:5] = imputer.transform(a[:, 4:5])"
      ],
      "metadata": {
        "id": "wFHcNPy8Nf-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(a)"
      ],
      "metadata": {
        "id": "7gLTp177NnzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- As we apply ML in Data Preprocessing, we need proper logical explanations.\n",
        "- Encoding to data , we transform 1 column into multiple columns like C1,C2, C3, etc. to avoid any data conflicts.\n",
        "- We need encode dependent variables (which we are going to predict) and independent variables.\n",
        "- In OnehotCoder function, it creates a new binary feature for each possible category and assigns a value of 1 to the feature of each sample that corresponds to its original category.\n",
        "- ColumnTransformers provide flexibility in preprocessing heterogeneous data and help avoid data leakage.\n",
        "- By specifying remainder='passthrough' , all remaining columns that were not specified in transformers, but present in the data passed to fit will be automatically passed through. This subset of columns is concatenated with the output of the transformers."
      ],
      "metadata": {
        "id": "kO4Lq6XNSJ6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "metadata": {
        "id": "gBs1d4fhU4ED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
        "a = np.array(ct.fit_transform(a))"
      ],
      "metadata": {
        "id": "7G2baum_VKOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(a)"
      ],
      "metadata": {
        "id": "euFbte0lVrDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Label encoding is a simple and effective way to convert categorical variables into numerical form. By using the LabelEncoder class from scikit-learn, you can easily encode your categorical data and prepare it for further analysis or input into machine learning algorithms.\n"
      ],
      "metadata": {
        "id": "AA7bkylTbs7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "b = le.fit_transform(b)"
      ],
      "metadata": {
        "id": "J-W0Z39dbv4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(b)"
      ],
      "metadata": {
        "id": "q1C17RVxcKYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We want our Machine Learning can learn from whatever has happened and apply all mathematical formulas automatically based on its learning.\n",
        "- We want to predict who are hospital & whether our prediction is same as what happened & find the accuracy.\n",
        "- The train_test_split() method is used to split our data into train and test sets. First, we need to divide our data into features (a) and labels (b). The dataframe gets divided into a_train, a_test, b_train, and b_test. a_train and b_train sets are used for training and fitting the model.\n",
        "- “random_state” is a parameter in train_test_split that controls the random number generator used to shuffle the data before splitting it. In other words, it ensures that the same randomization is used each time you run the code, resulting in the same splits of the data."
      ],
      "metadata": {
        "id": "msO_mfWrcNss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "a_train, a_test, b_train, b_test = train_test_split(a, b, test_size = 0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "OFA12CBEfFpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(a_train)"
      ],
      "metadata": {
        "id": "3f3T5bGuf2A3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(a_test)"
      ],
      "metadata": {
        "id": "pGkdlEL0f5Hu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(b_train)"
      ],
      "metadata": {
        "id": "20W_Ejzwf7Lo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(b_test)"
      ],
      "metadata": {
        "id": "lX-UAJ1_gTX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Feature Scaling is a technique to standardize the independent features present in the data in a fixed range.\n",
        "- It is performed during the data preprocessing to handle highly varying magnitudes or values or units.\n",
        "- Its a very effective technique that re-scales a feature value so that it has distribution with 0 mean values and variance equal to 1.\n",
        "              X(new)= X(i)-X(mean)/Standard Deviation\n"
      ],
      "metadata": {
        "id": "e68Uq6k-EYLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "a_train[:, 6:] = sc.fit_tranform(a_train[:])"
      ],
      "metadata": {
        "id": "aO9E2r8SKP43"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}